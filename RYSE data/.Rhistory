geom_point() +
labs(title = "Performance Metrics vs. Group Size",
x = "Average Group Size",
y = "Performance",
color = "Metric") +
theme_minimal()
df_long <- df_perf_regression_tree_multiplication %>%
pivot_longer(cols = c(MAE,RMSE),
names_to = "metric",
values_to = "value")
plot_error_multiply <- ggplot(df_long, aes(x = average_group_size, y = value, color = metric)) +
geom_line(size = 1) +
geom_point() +
labs(title = "Performance Metrics vs. Group Size",
x = "Average Group Size",
y = "Error",
color = "Metric") +
theme_minimal()
grid.arrange(plot_performance_multiply, plot_error_multiply, ncol = 2)
save.image("~/Ecole/M1/Stage/Internship_repo/RYSE data/RYSE_data.RData")
# Longitudinal study
## Packages ####
library(ggplot2)
library(dplyr)
library(missForest)
library(purrr)
library(rjags)
library(SSranef)
## Import the data ####
df <- readRDS("C:/Users/garan/Documents/Ecole/M1/Stage/Internship_repo/LORA/ds_forJan.rds")
load("~/Ecole/M1/Stage/Internship_repo/LORA/longitudinal_work_data.RData")
View(df_participation)
View(nb_PIP_alpha_pss)
View(nb_PIP_alpha_dh)
nb_PIP_alpha_dh<- nb_PIP(alpha_dh,seq(from=0.5,to=1,by=0.05))
source("data_analysis.R")
?extract_function
source("utils.R")
df <- readRDS("C:/Users/garan/Documents/Ecole/M1/Stage/Internship_repo/LORA/ds_forJan.rds")
load("~/Ecole/M1/Stage/Internship_repo/LORA/longitudinal_work_data.RData")
source("utils.R")
source("~/Ecole/M1/Stage/Internship_repo/LORA/utils.R")
## Packages ####
library(ggplot2)
library(dplyr)
library(missForest)
library(purrr)
library(rjags)
library(SSranef)
## Import the data and the functions ####
df <- readRDS("C:/Users/garan/Documents/Ecole/M1/Stage/Internship_repo/LORA/ds_forJan.rds")
load("~/Ecole/M1/Stage/Internship_repo/LORA/longitudinal_work_data.RData")
source("~/Ecole/M1/Stage/Internship_repo/LORA/utils.R")
nb_PIP_beta_pss<- nb_PIP(beta_pss,seq(from=0.5,to=1,by=0.05))
nb_PIP_beta_dh<- nb_PIP(beta_dh,seq(from=0.5,to=1,by=0.05))
View(nb_PIP_beta_pss)
View(nb_PIP_beta_dh)
pct_PIP <- function(alpha_res,percentages){
res <- data.frame(PIP=c(),pct_non_average=c(),pct_resilient=c(),pct_vulnerable=c())
for(percentage in percentages){
ranef_sum <- ranef_summary(alpha_res, ci = 0.95, digits = 2)
pct_resilient <- sum(ranef_sum$PIP>percentage&ranef_sum$Post.mean<0,na.rm=TRUE)/515*100
pct_vulnerable <- sum(ranef_sum$PIP>percentage&ranef_sum$Post.mean>0,na.rm=TRUE)/515*100
res <- rbind(res,data.frame(PIP=c(percentage),pct_non_average=c(pct_resilient+pct_vulnerable),pct_resilient=c(pct_resilient),pct_vulnerable=c(pct_vulnerable)))
}
return(res)
}
pct_PIP_alpha_pss<- pct_PIP(alpha_pss,seq(from=0.5,to=1,by=0.05))
pct_PIP_alpha_dh<- pct_PIP(alpha_dh,seq(from=0.5,to=1,by=0.05))
View(pct_PIP_alpha_pss)
View(pct_PIP_alpha_dh)
pct_PIP_beta_pss<- pct_PIP(beta_pss,seq(from=0.5,to=1,by=0.05))
pct_PIP_beta_dh<- pct_PIP(beta_dh,seq(from=0.5,to=1,by=0.05))
View(pct_PIP_beta_pss)
View(pct_PIP_beta_dh)
View(d)
d <- df_present_full_12
View(d)
source("~/Ecole/M1/Stage/Internship_repo/LORA/utils.R")
for(adversity in c("pss_sum","dh_sum")){
for(week_number in 1:25){
# Get the people present that week
index_present <- df$week==week_number&df$present
# Check if there are enough people (ie > 2) to do the regression.
if(sum(index_present)>2){
data_regression <- df[index_present,c(adversity,"ghq_sum")]
# Unadjusted linear model
lm_unadjusted <- lm(as.formula(paste("ghq_sum", "~", adversity)), data = data_regression)
# Identification of influencial points using Cook's D.
used_data <- model.frame(lm_unadjusted)
influencial_points <- which(cooks.distance(lm_unadjusted) > 4 / nrow(used_data))
used_rows <- as.numeric(rownames(used_data))
original_indices <- used_rows[influencial_points]
# Cleaned data for the LM
df_clean <- data_regression[-original_indices, ]
# Verify that there are at least two points for the adjusted regression
if(nrow(df_clean)>2){
# Adjusted linear model
lm_adjusted <- lm(as.formula(paste("ghq_sum", "~", adversity)), data = df_clean)
# Residuals of the adjusted linear model
predicted_all <- predict(lm_adjusted, newdata = data_regression)
residuals_all <- data_regression[["ghq_sum"]] - predicted_all
# Put the residual in the result df
if(adversity=="pss_sum"){
df[index_present,"residuals_ghq_pss"] <- residuals_all
}
else{
df[index_present,"residuals_ghq_dh"] <- residuals_all
}
# Get the grouping
if(adversity=="pss_sum"){
bins <- c(0,14,26,40)
}
else{
bins <- c(0,26,52,78,104,129)
}
df_result <-get_all_groups_small(data_regression,adversity,"ghq_sum",bins,lm_adjusted)
list_groups <- list("quantiles (15%)",
"quantiles (20%)",
"quantiles (25%)",
"pred. residuals (75%)",
"pred. residuals (60%)",
"pred. residuals (50%)",
"2SD",
"1SD",
"0.5SD",
"Kmeans")
for(group_name in list_groups){
df[index_present,paste0("tr_residuals_",group_name)] <- transformed_residuals(df_result,group_name,method="nothing")
}
}
}
}
}
for(adversity in c("pss_sum","dh_sum")){
for(week_number in 1:25){
# Get the people present that week
index_present <- df$week==week_number&df$present
# Check if there are enough people (ie > 2) to do the regression.
if(sum(index_present)>2){
data_regression <- df[index_present,c(adversity,"ghq_sum")]
# Unadjusted linear model
lm_unadjusted <- lm(as.formula(paste("ghq_sum", "~", adversity)), data = data_regression)
# Identification of influencial points using Cook's D.
used_data <- model.frame(lm_unadjusted)
influencial_points <- which(cooks.distance(lm_unadjusted) > 4 / nrow(used_data))
used_rows <- as.numeric(rownames(used_data))
original_indices <- used_rows[influencial_points]
# Cleaned data for the LM
df_clean <- data_regression[-original_indices, ]
# Verify that there are at least two points for the adjusted regression
if(nrow(df_clean)>2){
# Adjusted linear model
lm_adjusted <- lm(as.formula(paste("ghq_sum", "~", adversity)), data = df_clean)
# Residuals of the adjusted linear model
predicted_all <- predict(lm_adjusted, newdata = data_regression)
residuals_all <- data_regression[["ghq_sum"]] - predicted_all
# Put the residual in the result df
if(adversity=="pss_sum"){
df[index_present,"residuals_ghq_pss"] <- residuals_all
}
else{
df[index_present,"residuals_ghq_dh"] <- residuals_all
}
# Get the grouping
if(adversity=="pss_sum"){
bins <- c(0,14,26,40)
}
else{
bins <- c(0,26,52,78,104,129)
}
df_result <-get_all_groups_small(data_regression,adversity,"ghq_sum",bins,lm_adjusted)
list_groups <- list("quantiles (15%)",
"quantiles (20%)",
"quantiles (25%)",
"pred. residuals (75%)",
"pred. residuals (60%)",
"pred. residuals (50%)",
"2SD",
"1SD",
"0.5SD",
"Kmeans")
for(group_name in list_groups){
df[index_present,paste0("tr_residuals_",group_name)] <- transformed_residuals(df_result,group_name,method="nothing")
}
}
}
}
}
View(df)
source("~/Ecole/M1/Stage/Internship_repo/LORA/utils.R")
df <- readRDS("C:/Users/garan/Documents/Ecole/M1/Stage/Internship_repo/LORA/ds_forJan.rds")
source("~/Ecole/M1/Stage/Internship_repo/LORA/utils.R")
## Select, recode and sum variables and clean dataframe ####
# Select relevant variables and lines and create the week variable
dh_variables <- paste0("dh_",c(1:28,44:58))
ghq_variables <- paste0("ghq_", 1:28)
variables <- c("id","age","gender",ghq_variables,paste0("pss_",1:10),dh_variables)
df <- df[1:30966,variables]
df[["week"]] <- rep(0:25,1191)
df <- as.data.frame(lapply(df, function(x) as.numeric(as.character(x))))
# Create a variable indicating if the participant was there or not
df$present <- !apply(is.na(df[, ghq_variables]), 1, all)
# Replace negative values by NAs
for(variable in variables){
df[[variable]] <- ifelse(df[[variable]]>=0, df[[variable]], NA)
}
# Recode PSS
variables_to_recode <- paste0("pss_", c(4, 5, 7, 8))
for (variable in variables_to_recode) {
inverse_var <- paste0(variable, "_inverse")
df[[inverse_var]] <- ifelse(df[[variable]] %in% 0:4, 4 - df[[variable]], NA)
}
# Build total scores
pss_variables <- c(paste0("pss_",c(1:3,6,9,10)),paste0("pss_",c(4, 5, 7, 8),"_inverse"))
df[["pss_sum"]] <- rowSums(df[,pss_variables],na.rm = TRUE)
df[["ghq_sum"]] <- rowSums(df[,ghq_variables],,na.rm = TRUE)
df[["dh_sum"]] <- rowSums(df[,dh_variables],,na.rm = TRUE)
# Select relevant lines and final variables
final_variables <- c("id","week","present","age","gender","pss_sum","ghq_sum","dh_sum")
df <- df[,final_variables]
## Residualization + grouping ####
df[["residuals_ghq_pss"]] <- NA
df[["residuals_ghq_dh"]] <- NA
for(adversity in c("pss_sum","dh_sum")){
for(week_number in 1:25){
# Get the people present that week
index_present <- df$week==week_number&df$present
# Check if there are enough people (ie > 2) to do the regression.
if(sum(index_present)>2){
data_regression <- df[index_present,c(adversity,"ghq_sum")]
# Unadjusted linear model
lm_unadjusted <- lm(as.formula(paste("ghq_sum", "~", adversity)), data = data_regression)
# Identification of influencial points using Cook's D.
used_data <- model.frame(lm_unadjusted)
influencial_points <- which(cooks.distance(lm_unadjusted) > 4 / nrow(used_data))
used_rows <- as.numeric(rownames(used_data))
original_indices <- used_rows[influencial_points]
# Cleaned data for the LM
df_clean <- data_regression[-original_indices, ]
# Verify that there are at least two points for the adjusted regression
if(nrow(df_clean)>2){
# Adjusted linear model
lm_adjusted <- lm(as.formula(paste("ghq_sum", "~", adversity)), data = df_clean)
# Residuals of the adjusted linear model
predicted_all <- predict(lm_adjusted, newdata = data_regression)
residuals_all <- data_regression[["ghq_sum"]] - predicted_all
# Put the residual in the result df
if(adversity=="pss_sum"){
df[index_present,"residuals_ghq_pss"] <- residuals_all
}
else{
df[index_present,"residuals_ghq_dh"] <- residuals_all
}
# Get the grouping
if(adversity=="pss_sum"){
bins <- c(0,14,26,40)
}
else{
bins <- c(0,26,52,78,104,129)
}
df_result <-get_all_groups_small(data_regression,adversity,"ghq_sum",bins,lm_adjusted)
list_groups <- list("quantiles (15%)",
"quantiles (20%)",
"quantiles (25%)",
"pred. residuals (75%)",
"pred. residuals (60%)",
"pred. residuals (50%)",
"2SD",
"1SD",
"0.5SD",
"Kmeans")
for(group_name in list_groups){
df[index_present,paste0("tr_residuals_",group_name)] <- transformed_residuals(df_result,group_name,method="nothing")
}
}
}
}
}
## Residualization + grouping ####
df[["residuals_ghq_pss"]] <- NA
df[["residuals_ghq_dh"]] <- NA
source("~/Ecole/M1/Stage/Internship_repo/LORA/utils.R")
source("~/Ecole/M1/Stage/Internship_repo/LORA/utils.R")
for(adversity in c("pss_sum","dh_sum")){
for(week_number in 1:25){
print(week_number)
# Get the people present that week
index_present <- df$week==week_number&df$present
# Check if there are enough people (ie > 2) to do the regression.
if(sum(index_present)>2){
data_regression <- df[index_present,c(adversity,"ghq_sum")]
# Unadjusted linear model
lm_unadjusted <- lm(as.formula(paste("ghq_sum", "~", adversity)), data = data_regression)
# Identification of influencial points using Cook's D.
used_data <- model.frame(lm_unadjusted)
influencial_points <- which(cooks.distance(lm_unadjusted) > 4 / nrow(used_data))
used_rows <- as.numeric(rownames(used_data))
original_indices <- used_rows[influencial_points]
# Cleaned data for the LM
df_clean <- data_regression[-original_indices, ]
# Verify that there are at least two points for the adjusted regression
if(nrow(df_clean)>2){
# Adjusted linear model
lm_adjusted <- lm(as.formula(paste("ghq_sum", "~", adversity)), data = df_clean)
# Residuals of the adjusted linear model
predicted_all <- predict(lm_adjusted, newdata = data_regression)
residuals_all <- data_regression[["ghq_sum"]] - predicted_all
# Put the residual in the result df
if(adversity=="pss_sum"){
df[index_present,"residuals_ghq_pss"] <- residuals_all
}
else{
df[index_present,"residuals_ghq_dh"] <- residuals_all
}
# Get the grouping
if(adversity=="pss_sum"){
bins <- c(0,14,26,40)
}
else{
bins <- c(0,26,52,78,104,129)
}
df_result <-get_all_groups_small(df_clean,adversity,"ghq_sum",bins,lm_adjusted)
list_groups <- list("quantiles (15%)",
"quantiles (20%)",
"quantiles (25%)",
"pred. residuals (75%)",
"pred. residuals (60%)",
"pred. residuals (50%)",
"2SD",
"1SD",
"0.5SD",
"Kmeans")
for(group_name in list_groups){
df[index_present,paste0("tr_residuals_",group_name)] <- transformed_residuals(df_result,group_name,method="nothing")
}
}
}
}
}
for(adversity in c("pss_sum","dh_sum")){
for(week_number in 1:25){
print(week_number)
# Get the people present that week
index_present <- df$week==week_number&df$present
# Check if there are enough people (ie > 2) to do the regression.
if(sum(index_present)>2){
data_regression <- df[index_present,c(adversity,"ghq_sum")]
# Unadjusted linear model
lm_unadjusted <- lm(as.formula(paste("ghq_sum", "~", adversity)), data = data_regression)
# Identification of influencial points using Cook's D.
used_data <- model.frame(lm_unadjusted)
influencial_points <- which(cooks.distance(lm_unadjusted) > 4 / nrow(used_data))
used_rows <- as.numeric(rownames(used_data))
original_indices <- used_rows[influencial_points]
# Cleaned data for the LM
df_clean <- data_regression[-original_indices, ]
# Verify that there are at least two points for the adjusted regression
if(nrow(df_clean)>2){
# Adjusted linear model
lm_adjusted <- lm(as.formula(paste("ghq_sum", "~", adversity)), data = df_clean)
# Residuals of the adjusted linear model
predicted_all <- predict(lm_adjusted, newdata = data_regression)
residuals_all <- data_regression[["ghq_sum"]] - predicted_all
# Put the residual in the result df
if(adversity=="pss_sum"){
df[index_present,"residuals_ghq_pss"] <- residuals_all
}
else{
df[index_present,"residuals_ghq_dh"] <- residuals_all
}
# Get the grouping
if(adversity=="pss_sum"){
bins <- c(0,14,26,40)
}
else{
bins <- c(0,26,52,78,104,129)
}
df_result <-get_all_groups_small(df_clean,adversity,"ghq_sum",bins,lm_adjusted)
list_groups <- list("quantiles (15%)",
"quantiles (20%)",
"quantiles (25%)",
"pred. residuals (75%)",
"pred. residuals (60%)",
"pred. residuals (50%)",
"2SD",
"1SD",
"0.5SD",
"Kmeans")
print(df_result)
for(group_name in list_groups){
df[index_present,paste0("tr_residuals_",group_name)] <- transformed_residuals(df_result,group_name,method="nothing")
}
}
}
}
}
for(adversity in c("pss_sum","dh_sum")){
for(week_number in 1:25){
print(week_number)
# Get the people present that week
index_present <- df$week==week_number&df$present
# Check if there are enough people (ie > 2) to do the regression.
if(sum(index_present)>2){
data_regression <- df[index_present,c(adversity,"ghq_sum")]
# Unadjusted linear model
lm_unadjusted <- lm(as.formula(paste("ghq_sum", "~", adversity)), data = data_regression)
# Identification of influencial points using Cook's D.
used_data <- model.frame(lm_unadjusted)
influencial_points <- which(cooks.distance(lm_unadjusted) > 4 / nrow(used_data))
used_rows <- as.numeric(rownames(used_data))
original_indices <- used_rows[influencial_points]
# Cleaned data for the LM
df_clean <- data_regression[-original_indices, ]
# Verify that there are at least two points for the adjusted regression
if(nrow(df_clean)>2){
# Adjusted linear model
lm_adjusted <- lm(as.formula(paste("ghq_sum", "~", adversity)), data = df_clean)
# Residuals of the adjusted linear model
predicted_all <- predict(lm_adjusted, newdata = data_regression)
residuals_all <- data_regression[["ghq_sum"]] - predicted_all
# Put the residual in the result df
if(adversity=="pss_sum"){
df[index_present,"residuals_ghq_pss"] <- residuals_all
}
else{
df[index_present,"residuals_ghq_dh"] <- residuals_all
}
# Get the grouping
if(adversity=="pss_sum"){
bins <- c(0,14,26,40)
}
else{
bins <- c(0,26,52,78,104,129)
}
df_result <- get_all_groups_small(df_clean,adversity,"ghq_sum",bins,lm_adjusted)
print("I did df_result")
list_groups <- list("quantiles (15%)",
"quantiles (20%)",
"quantiles (25%)",
"pred. residuals (75%)",
"pred. residuals (60%)",
"pred. residuals (50%)",
"2SD",
"1SD",
"0.5SD",
"Kmeans")
for(group_name in list_groups){
df[index_present,paste0("tr_residuals_",group_name)] <- transformed_residuals(df_result,group_name,method="nothing")
}
}
}
}
}
df[["residuals_ghq_pss"]] <- NA
df[["residuals_ghq_dh"]] <- NA
for(adversity in c("pss_sum","dh_sum")){
for(week_number in 1:25){
print(week_number)
# Get the people present that week
index_present <- df$week==week_number&df$present
# Check if there are enough people (ie > 2) to do the regression.
if(sum(index_present)>2){
data_regression <- df[index_present,c(adversity,"ghq_sum")]
# Unadjusted linear model
lm_unadjusted <- lm(as.formula(paste("ghq_sum", "~", adversity)), data = data_regression)
# Identification of influencial points using Cook's D.
used_data <- model.frame(lm_unadjusted)
influencial_points <- which(cooks.distance(lm_unadjusted) > 4 / nrow(used_data))
used_rows <- as.numeric(rownames(used_data))
original_indices <- used_rows[influencial_points]
# Cleaned data for the LM
df_clean <- data_regression[-original_indices, ]
# Verify that there are at least two points for the adjusted regression
if(nrow(df_clean)>2){
# Adjusted linear model
lm_adjusted <- lm(as.formula(paste("ghq_sum", "~", adversity)), data = df_clean)
# Residuals of the adjusted linear model
predicted_all <- predict(lm_adjusted, newdata = data_regression)
residuals_all <- data_regression[["ghq_sum"]] - predicted_all
# Put the residual in the result df
if(adversity=="pss_sum"){
df[index_present,"residuals_ghq_pss"] <- residuals_all
}
else{
df[index_present,"residuals_ghq_dh"] <- residuals_all
}
# Get the grouping
if(adversity=="pss_sum"){
bins <- c(0,14,26,40)
}
else{
bins <- c(0,26,52,78,104,129)
}
df_result <- get_all_groups_small(df_clean,adversity,"ghq_sum",bins,lm_adjusted)
list_groups <- list("quantiles (15%)",
"quantiles (20%)",
"quantiles (25%)",
"pred. residuals (75%)",
"pred. residuals (60%)",
"pred. residuals (50%)",
"2SD",
"1SD",
"0.5SD",
"Kmeans")
for(group_name in list_groups){
df[index_present,paste0("tr_residuals_",group_name)] <- transformed_residuals(df_result,group_name,method="nothing")
}
}
}
}
}
