# Base graph with points and linear regression
plot <- ggplot(df, aes(x = .data[[adversity]], y = .data[[outcome]])) +
geom_point(shape = 1, size = 0.8) +
geom_abline(intercept = intercept, slope = slope, color = "grey", linetype = "solid") +
labs(
x = adversity,
y = outcome,
title = main,
fill = "Interval"
) +
theme_minimal(base_size = 10) +
theme(plot.title = element_text(size = 10))
# Combine all intervals parsed in the function
all_preds <- do.call(rbind, lapply(seq_along(preds), function(i) {
pred <- preds[[i]]
pred[[outcome]]   <- df[[outcome]]
pred[[adversity]] <- df[[adversity]]
pred$label <- labels[i]
pred
}))
all_preds$label <- factor(all_preds$label, levels = labels)
# Add ribbons for every intervals
plot <- plot +
geom_ribbon(
data = all_preds,
aes(
x = .data[[adversity]],
ymin = lwr,
ymax = upr,
fill = label,
group = label
),
alpha = 0.4,
inherit.aes = FALSE
) +
scale_fill_manual(values = colors)
# Resilient / Vulnerable annotations
if (slope < 0) {
plot <- plot +
geom_text(x = max(na.omit(df[[adversity]])) - 5,
y = max(na.omit(df[[outcome]])) - 5,
label = "Resilient", alpha = 0.2, color = "grey") +
geom_text(x = min(na.omit(df[[adversity]])) + 5,
y = min(na.omit(df[[outcome]])) + 5,
label = "Vulnerable", alpha = 0.2, color = "grey")
} else {
plot <- plot +
geom_text(x = min(na.omit(df[[adversity]])) + 5,
y = max(na.omit(df[[outcome]])) - 5,
label = "Vulnerable", alpha = 0.2, color = "grey") +
geom_text(x = max(na.omit(df[[adversity]])) - 5,
y = min(na.omit(df[[outcome]])) + 5,
label = "Resilient", alpha = 0.2, color = "grey")
}
return(plot)
}
## Quantile residuals ####
# We want the quantile_sub lowest residuals and quantile_sup biggest residuals
get_groups_quantile <- function(residuals,quantile_sub,quantile_sup,is_resilience_positive){
n <- sum(!is.na(residuals))
n_sub <- trunc(n*quantile_sub)
n_sup <- trunc(n*quantile_sup)
index_ordered_residuals <- order(residuals)
res <- rep(NA, length(residuals))
res[!is.na(residuals)] <- "average"
if(is_resilience_positive){
# Lowest residuals -> vulnerable
for(i in 1:n_sub){
index <- index_ordered_residuals[i]
res[[index]] <- "vulnerable"
}
# Biggest residuals -> resilient
for(i in n:(n-n_sup)){
index <- index_ordered_residuals[i]
res[[index]] <- "resilient"
}
}
else{
# Lowest residuals -> resilient
for(i in 1:n_sub){
index <- index_ordered_residuals[i]
res[[index]] <- "resilient"
}
# Biggest residuals -> vulnerable
for(i in n:(n-n_sup)){
index <- index_ordered_residuals[i]
res[[index]] <- "vulnerable"
}
}
return(res)
}
## Credibility residuals ##########
# We can do the same with a bayesian approach with a credibility interval (for the mean and for predicted values)
# Function to build the credibility intervals from the bayesian adjusted lm
get_credibility_intervals <- function(lm_adjusted_cred,newdata,lwr=0.025,upr=0.975){
# Posterior linear prediction
preds <- posterior_linpred(lm_adjusted_cred,
newdata = newdata[!is.na(newdata[,c(adversity_string)]),],
draws = 1000,
transform = TRUE)
# Ensure preds is a matrix with rows = draws, cols = observations
if (is.null(dim(preds))) {
preds <- matrix(preds, nrow = 1000)
}
# Compute credible intervals per observation (apply over columns)
intervals <- t(apply(preds, 2, quantile, probs = c(lwr, upr)))
# Formating the result
res <- data.frame(lwr=c(), upr=c())
counter <- 1
# Adding NA or computed value for every point of the dataset
for(i in 1:nrow(newdata)){
if(!is.na(newdata[i,1])){
res[i,"lwr"] <- intervals[counter,1]
res[i,"upr"] <- intervals[counter,2]
counter <- counter + 1
}
else{
res[i,"lwr"] <- NA
res[i,"upr"] <- NA
}
}
return(res)
}
## Standard deviation ########
get_groups_sd <- function(df, residuals, bins, adversity_string, is_resilience_positive, sd_multiplicator=1){
res_SD <- c()
bin_labels <- rep(NA, nrow(df))  # To stock the bin of each line.
# Calculate the SD for each bin
for (i in 1:(length(bins) - 1)) {
in_bin <- df[[adversity_string]] > bins[i] & df[[adversity_string]] < bins[i + 1]
bin_labels[in_bin] <- i #We save the i indice of the bin for each line that's in the bin
residuals_bin <- residuals[in_bin]
res_SD[i] <- sd(residuals_bin, na.rm = TRUE)
}
# Flag each residual as resilient, average or vulnerable
groups_sd <- rep(NA, nrow(df))
for (i in seq_along(residuals)) {
bin_i <- bin_labels[i]
# Skip if bin or residual is NA
if (is.na(bin_i) || is.na(residuals[i])) next
# Recuperate the SD for the bin and the residual of the current point
sd_i <- res_SD[bin_i]*sd_multiplicator
res <- residuals[i]
# Look at the value of the residuals with respect to the SD
if (abs(res) <= sd_i) {
groups_sd[i] <- "average"
}
# Bigger residual -> resilient
else if(is_resilience_positive){
if (res > sd_i) {
groups_sd[i] <- "resilient"
} else if (res < -sd_i) {
groups_sd[i] <- "vulnerable"
}
}
# Bigger residual -> vulnerable
else{
if (res > sd_i) {
groups_sd[i] <- "vulnerable"
}
else if (res < -sd_i) {
groups_sd[i] <- "resilient"
}
}
}
return(list(groups_sd=groups_sd,res_SD=res_SD*sd_multiplicator))
}
# Visualization function for the SD intervals
visualization_sd_intervals <- function(df,adversity,outcome,adjusted_lm,bins,res,main="SD Intervals"){
# Adjusted linear model coefficients
intercept <- coef(adjusted_lm)[1]
slope     <- coef(adjusted_lm)[2]
# Base graph with points and regression line
plot <- ggplot(df, aes(x = .data[[adversity]], y = .data[[outcome]])) +
geom_point(shape=1,size=0.8) +
geom_abline(intercept = intercept, slope = slope, color = "grey", linetype = "solid") +
labs(
x = adversity,
y = outcome,
title = main,
fill = "Interval"
) +
theme_minimal(base_size = 10) +
theme(plot.title = element_text(size = 10))
# Color the area for each result
all_polygons <- data.frame()
for (i in seq_along(res)){
res_SD <- res[[i]]$res_SD
for(j in 1:(length(bins)-1)){
point_j <- bins[[j]]
point_j1 <- bins[[j+1]]
fit_j <- intercept + slope * point_j
fit_j1 <- intercept + slope * point_j1
sd_j <- res_SD[[j]]
df_area <- data.frame(
x = c(point_j, point_j, point_j1, point_j1),
y = c(fit_j - sd_j, fit_j + sd_j, fit_j1 + sd_j, fit_j1 - sd_j),
group = paste0("poly_", i, "_", j),
fill_factor = names_sd[[i]]
)
all_polygons <- rbind(all_polygons, df_area)
}
}
# Add polygons to the main plot
plot <- plot +
geom_polygon(data = all_polygons, aes(x = x, y = y, group = group, fill = fill_factor), alpha = 0.3, color = NA) +
scale_fill_manual(values = c("2SD" = "lightblue", "1SD" = "skyblue2", "0.5SD" = "deepskyblue3"))
# Add resilient and vulnerable text
if(slope < 0){
plot <-plot + geom_text(x=max(na.omit(df[[adversity]]))-5,y=max(na.omit(df[[outcome]]))-5,label="Resilient",alpha=0.2,color="grey") + geom_text(x=min(na.omit(df[[adversity]]))+5,y=min(na.omit(df[[outcome]]))+5,label="Vulnerable",alpha=0.2,color="grey")
}
else{
plot <- plot + geom_text(x=min(na.omit(df[[adversity]]))+5,y=max(na.omit(df[[outcome]]))-5,label="Vulnerable",alpha=0.2,color="grey") + geom_text(x=max(na.omit(df[[adversity]]))-5,y=min(na.omit(df[[outcome]]))+5,label="Resilient",alpha=0.2,color="grey")
}
return(plot)
}
## Results presentation commands ##########
# Example 3
df <- df_CA
adversity_string <- "T1_FAS"
outcome_string <- "T1_BDI_II"
outcome <- df_CA$T1_BDI_II
bins <- bins_FAS
res <- adjusted_fit(df=df,adversity=adversity_string,outcome=outcome_string)
# Example 2
df <- df_CA
adversity_string <- "T1_CPTS"
outcome_string <- "T1_WES_total"
outcome <- df_CA$T1_WES_total
bins <- bins_CPTS
res <- adjusted_fit(df=df_CA,adversity="T1_CPTS",outcome="T1_WES_total",main="Adjusted and unadjusted linear regression for CPTS and WES for Canada at T1",xlab="CPTS",ylab="WES")
# Example 1
df <- df_CA
adversity_string <- "T1_CPTS"
outcome_string <- "T1_BDI_II"
outcome <- df_CA$T1_BDI_II
bins <- bins_CPTS
res <- adjusted_fit(df=df,adversity=adversity_string,outcome=outcome_string)
# Get the info
lm_adjusted <- res$lm_adjusted
lm_adjusted_cred <- res$lm_adjusted_cred
residuals <- res$residuals_adjusted
plot <- res$plot
resilience_sign <- lm_adjusted$coefficients[2]<0
# Raw residuals
groups_raw <- get_groups_raw_residuals(residuals,is_resilience_positive=resilience_sign)
df_n_groups <- data.frame(resilient = sum(groups_raw=="resilient", na.rm=TRUE), average = sum(groups_raw=="average", na.rm=TRUE), vulnerable = sum(groups_raw=="vulnerable", na.rm=TRUE), row.names=c("raw residuals"))
# Confidence intervals
# Prediction
preds_conf <- list(
as.data.frame(predict(lm_adjusted, newdata = df, interval = "prediction", level = 0.75)),
as.data.frame(predict(lm_adjusted, newdata = df, interval = "prediction", level = 0.6)),
as.data.frame(predict(lm_adjusted, newdata = df, interval = "prediction", level = 0.5)),
as.data.frame(predict(lm_adjusted, newdata = df, interval = "confidence", level = 0.99)),
as.data.frame(predict(lm_adjusted, newdata = df, interval = "confidence", level = 0.95))
)
# Names for the predictions
names_conf <- list(
"pred. residuals (75%)",
"pred. residuals (60%)",
"pred. residuals (50%)",
"conf. residuals (99%)",
"conf. residuals (95%)"
)
# Get groups and update df_n_groups
groups_confidence <- list()
for(i in 1:length(preds_conf)){
groups <- get_groups_intervals(outcome, preds_conf[[i]],is_resilience_positive=resilience_sign)
groups_confidence[[ names_conf[[i]] ]] <- groups
df_n_groups <- rbind(df_n_groups,
data.frame(resilient = sum(groups=="resilient", na.rm=TRUE), average = sum(groups=="average", na.rm=TRUE), vulnerable = sum(groups=="vulnerable", na.rm=TRUE), row.names=c(names_conf[[i]])))
}
# Quantiles
# Quantile values -> Can be asymetric (looking at the QQ-plot ?)
list_quantile_sub <- list(0.05,0.1,0.15,0.25)
list_quantile_sup <- list(0.05,0.1,0.15,0.25)
# Names
names <- list(
"quantiles (5%)",
"quantiles (10%)",
"quantiles (15%)",
"quantiles (25%)"
)
# Get groups and update df_n_groups
groups_quantile <- list()
for(i in 1:length(list_quantile_sub)){
groups <- get_groups_quantile(residuals,list_quantile_sub[[i]],list_quantile_sup[[i]],is_resilience_positive=resilience_sign)
groups_quantile[[ names[[i]] ]] <- groups
df_n_groups <- rbind(df_n_groups,
data.frame(resilient = sum(groups=="resilient", na.rm=TRUE), average = sum(groups=="average", na.rm=TRUE), vulnerable = sum(groups=="vulnerable", na.rm=TRUE), row.names=c(names[[i]])))
}
# Credibility intervals
# Predictions
preds_cred <- list(
get_credibility_intervals(lm_adjusted_cred,newdata=df[c(adversity_string)],lwr=0.0005,upr=0.9995),
get_credibility_intervals(lm_adjusted_cred,newdata=df[c(adversity_string)],lwr=0.005,upr=0.995),
get_credibility_intervals(lm_adjusted_cred,newdata=df[c(adversity_string)],lwr=0.025,upr=0.975),
get_credibility_intervals(lm_adjusted_cred,newdata=df[c(adversity_string)],lwr=0.05,upr=0.95),
get_credibility_intervals(lm_adjusted_cred,newdata=df[c(adversity_string)],lwr=0.125,upr=0.875),
get_credibility_intervals(lm_adjusted_cred,newdata=df[c(adversity_string)],lwr=0.25,upr=0.75)
)
# Names for the predictions
names_cred <- list(
"cred. 99.9%",
"cred. 99%",
"cred. 95%",
"cred. 90%",
"cred. 75%",
"cred. 50%"
)
# Get groups and update df_n_groups
groups_credibility <- list()
for(i in 1:length(preds_cred)){
groups <- get_groups_intervals(outcome, preds_cred[[i]],is_resilience_positive=resilience_sign)
groups_credibility[[ names_cred[[i]] ]] <- groups
df_n_groups <- rbind(df_n_groups,
data.frame(resilient = sum(groups=="resilient", na.rm=TRUE), average = sum(groups=="average", na.rm=TRUE), vulnerable = sum(groups=="vulnerable", na.rm=TRUE), row.names=c(names_cred[[i]])))
}
# Standard deviation
list_sd_multiplicator <- list(2,1,0.5)
names_sd <- list("2SD","1SD","0.5SD")
groups_sd <- list()
res <- list()
for(i in 1:length(list_sd_multiplicator)){
res[[i]] <- get_groups_sd(df, residuals, bins, adversity_string, resilience_sign, sd_multiplicator=list_sd_multiplicator[[i]])
groups <- res[[i]]$groups_sd
groups_sd[[ names_sd[[i]] ]] <- groups
df_n_groups <- rbind(df_n_groups,
data.frame(resilient = sum(groups=="resilient", na.rm=TRUE), average = sum(groups=="average", na.rm=TRUE), vulnerable = sum(groups=="vulnerable", na.rm=TRUE), row.names=c(names_sd[[i]])))
}
## Results #########
# Cardinal of each group
View(df_n_groups)
# Groups
groups_raw
groups_confidence
groups_quantile
groups_credibility
groups_sd
# Visualizations
visualization_raw_residuals(df,adversity_string,outcome_string,lm_adjusted,groups_raw)
visualization_intervals(df=df,adversity=adversity_string,outcome=outcome_string,adjusted_lm =lm_adjusted,preds_conf,names_conf,main="Confidence intervals")
visualization_intervals(df=df,adversity=adversity_string,outcome=outcome_string,adjusted_lm =lm_adjusted_cred,preds_cred,names_cred,main="Credibility intervals")
visualization_sd_intervals(df,adversity=adversity_string,outcome=outcome_string,adjusted_lm=lm_adjusted,bins=bins,res=res,main="SD Intervals")
qqnorm(residuals)
qqline(residuals)
## How to choose the right clusturing method ... ? ######
# We will use unsupervised clusturing algorithms such has k-means and hclust to see what are the groups are obtained
# and are they corresponding to the groups we found with our previous methods.
# Ideas :
# We want 3 clusters.
# We will test if only the residuals, the residuals and the adversity and outcome variable and only the adversity and the outcome.
# For kmeans : nstart + test to give the orignal centers (highest residual, smallest residual and 0) or not for the k-means algorithm.
# For hierachical clusturing : try different distances and aggregation methods
## K-means ######
get_groups_kmeans <- function(actual, residuals, is_resilience_positive) {
# Initialize result vector
groups <- rep(NA_character_, length(actual))
# Omit NA values from residuals and store corresponding indices
non_na_indices <- which(!is.na(residuals))
clean_residuals <- residuals[non_na_indices]
# Create dataframe for clustering
df_residuals <- data.frame(residual = clean_residuals)
# Run K-means clustering with 3 centers
clust <- kmeans(df_residuals$residual, centers = 3)
df_residuals$cluster <- as.factor(clust$cluster)
# Calculate mean residual for each cluster
cluster_means <- tapply(df_residuals$residual, df_residuals$cluster, mean)
# Identify cluster corresponding to min, average, and max
ordered_clusters <- names(sort(cluster_means))
min_group <- ordered_clusters[1]
average_group <- ordered_clusters[2]
max_group <- ordered_clusters[3]
# Assign labels based on cluster and resilience sign
for (i in seq_along(non_na_indices)) {
idx <- non_na_indices[i]
cluster_label <- as.character(df_residuals$cluster[i])
if (is_resilience_positive) {
if (cluster_label == max_group) {
groups[idx] <- "resilient"
} else if (cluster_label == min_group) {
groups[idx] <- "vulnerable"
} else {
groups[idx] <- "average"
}
} else {
if (cluster_label == max_group) {
groups[idx] <- "vulnerable"
} else if (cluster_label == min_group) {
groups[idx] <- "resilient"
} else {
groups[idx] <- "average"
}
}
}
return(groups)
}
visualization_kmeans <- function(df,adversity,outcome,adjusted_lm,groups,main="Kmeans clusturing"){
# Adjusted linear regression coefficient for the plot
intercept <- coef(adjusted_lm)[1]
slope     <- coef(adjusted_lm)[2]
# Add groups to the temporary df to color the points
df$group <- factor(groups, levels = c("resilient", "average", "vulnerable",NA))
# Viz
plot <- ggplot(df, aes(x = .data[[adversity]], y = .data[[outcome]], color = group)) +
geom_point(shape=1,size=0.8) +
geom_abline(intercept = intercept, slope = slope, color = "grey", linetype = "dashed") +
labs(
x = adversity,
y = outcome,
title = main,
color = "Group"
) +
theme_minimal(base_size = 10) +
theme(plot.title = element_text(size = 10))+
scale_color_manual(values = c("resilient" = "skyblue", "average" = "grey", "vulnerable" = "coral"))
# Add resilient and vulnerable text
if(slope < 0){
plot <-plot + geom_text(x=max(na.omit(df[[adversity]]))-5,y=max(na.omit(df[[outcome]]))-5,label="Resilient",alpha=0.2,color="grey") + geom_text(x=min(na.omit(df[[adversity]]))+5,y=min(na.omit(df[[outcome]]))+5,label="Vulnerable",alpha=0.2,color="grey")
}
else{
plot <- plot + geom_text(x=min(na.omit(df[[adversity]]))+5,y=max(na.omit(df[[outcome]]))-5,label="Vulnerable",alpha=0.2,color="grey") + geom_text(x=max(na.omit(df[[adversity]]))-5,y=min(na.omit(df[[outcome]]))+5,label="Resilient",alpha=0.2,color="grey")
}
return(plot)
}
groups_kmeans <- get_groups_kmeans(outcome, residuals, resilience_sign)
df_n_groups <- rbind(df_n_groups,
data.frame(resilient = sum(groups_kmeans=="resilient", na.rm=TRUE), average = sum(groups_kmeans=="average", na.rm=TRUE), vulnerable = sum(groups_kmeans=="vulnerable", na.rm=TRUE), row.names=c("K-means")))
visualization_kmeans(df,adversity_string,outcome_string,lm_adjusted,groups_kmeans)
## Comparison of 2 groups #####
number_equal_predictions <- function(groups1,groups2){
print(table(groups1,groups2))
n_total <- sum(!is.na(groups1))
n_common <- sum(groups1==groups2,na.rm=TRUE)
return(list(n_common=n_common,proportion=n_common/n_total))
}
number_equal_predictions(groups_kmeans,groups_quantile[[4]])
?table
number_equal_predictions <- function(groups1,groups2,name1="Group1",name2="Group2"){
print(table(groups1,groups2),dnn=list(name1,name2))
n_total <- sum(!is.na(groups1))
n_common <- sum(groups1==groups2,na.rm=TRUE)
return(list(n_common=n_common,proportion=n_common/n_total))
}
number_equal_predictions(groups_kmeans,groups_quantile[[4]])
number_equal_predictions <- function(groups1,groups2,name1="Group1",name2="Group2"){
print(table(groups1,groups2),dnn=list(name1,name2))
n_total <- sum(!is.na(groups1))
n_common <- sum(groups1==groups2,na.rm=TRUE)
return(list(n_common=n_common,proportion=n_common/n_total))
}
number_equal_predictions(groups_kmeans,groups_quantile[[4]])
number_equal_predictions <- function(groups1,groups2,name1="Group1",name2="Group2"){
print(table(groups1,groups2,dnn=list(name1,name2)))
n_total <- sum(!is.na(groups1))
n_common <- sum(groups1==groups2,na.rm=TRUE)
return(list(n_common=n_common,proportion=n_common/n_total))
}
number_equal_predictions(groups_kmeans,groups_quantile[[4]])
number_equal_predictions <- function(groups1,groups2,name1="Group1",name2="Group2"){
print(table(groups1,groups2,dnn=list(name1,name2)))
n_total <- sum(!is.na(groups1))
n_common <- sum(groups1==groups2,na.rm=TRUE)
return(list(n_common=n_common,proportion=n_common/n_total))
}
number_equal_predictions(groups_kmeans,groups_quantile[[4]],name1="Kmeans",name2="Quantile 25%")
number_equal_predictions <- function(groups1,groups2,name1="Group1",name2="Group2"){
table <- table(groups1,groups2,dnn=list(name1,name2))
n_total <- sum(!is.na(groups1))
n_common <- sum(groups1==groups2,na.rm=TRUE)
return(list(table=table,n_common=n_common,proportion=n_common/n_total))
}
number_equal_predictions(groups_kmeans,groups_quantile[[4]],name1="Kmeans",name2="Quantile 25%")
groups_kmeans <- get_groups_kmeans(outcome, residuals, resilience_sign)
number_equal_predictions(groups_kmeans,groups_quantile[[4]],name1="Kmeans",name2="Quantile 25%")
visualization_comparison <- function(df, adversity_string, outcome_string, adjusted_lm, groups1, groups2, name1 = "Groups1", name2 = "Groups2") {
# Adjusted linear regression coefficient for the plot
intercept <- coef(adjusted_lm)[1]
slope     <- coef(adjusted_lm)[2]
# Add groups to the temporary df to color the points
df$groups1 <- factor(groups1, levels = c("resilient", "average", "vulnerable", NA))
df$groups2 <- factor(groups2, levels = c("resilient", "average", "vulnerable", NA))
# Base plot with first clustering
plot <- ggplot(df, aes(x = .data[[adversity_string]], y = .data[[outcome_string]])) +
# Groups1 shown with hollow circles
geom_point(aes(color = groups1), shape = 1, size = 1.2,alpha=0.8) +
# Groups2 shown with cross
geom_point(aes(shape = groups2),shape= 3, size = 1,alpha=0.8) +
geom_abline(intercept = intercept, slope = slope, color = "grey", linetype = "dashed") +
labs(
x = adversity_string,
y = outcome_string,
title = paste(name1, "vs", name2,"clusturing"),
color = name1,
shape = name2
) +
theme_minimal(base_size = 10) +
theme(plot.title = element_text(size = 10)) +
scale_color_manual(values = c("resilient" = "skyblue", "average" = "grey", "vulnerable" = "coral"))
# Add resilient and vulnerable text
if (slope < 0) {
plot <- plot +
geom_text(x = max(na.omit(df[[adversity_string]])) - 5, y = max(na.omit(df[[outcome_string]])) - 5, label = "Resilient", alpha = 0.2, color = "grey") +
geom_text(x = min(na.omit(df[[adversity_string]])) + 5, y = min(na.omit(df[[outcome_string]])) + 5, label = "Vulnerable", alpha = 0.2, color = "grey")
} else {
plot <- plot +
geom_text(x = min(na.omit(df[[adversity_string]])) + 5, y = max(na.omit(df[[outcome_string]])) - 5, label = "Vulnerable", alpha = 0.2, color = "grey") +
geom_text(x = max(na.omit(df[[adversity_string]])) - 5, y = min(na.omit(df[[outcome_string]])) + 5, label = "Resilient", alpha = 0.2, color = "grey")
}
return(plot)
}
visualization_comparison(df_CA,adversity_string,outcome_string,lm_adjusted,groups_kmeans,groups_quantile[[4]],name1="Kmeans",name2="Quantile 25%")
