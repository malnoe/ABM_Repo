}
}
else if(method=="log_multiply"){
# Multiply the residual by log(1+adversity)
res <- c(res,df_result[i,"residuals"]*log1p(1+df_result[i,"adversity"]))
}
else{
# Multiply the residual by the adversity
res <- c(res,df_result[i,"residuals"]*df_result[i,"adversity"])
}
}
}
return(res)
}
# Function for regression trees
regression_tree <- function(df,df_result,list_group_names,predictors=explication_vars,method="nothing"){
set.seed(1) # For reproductibility
res <- data.frame()
residuals <- df_result[["residuals"]]
for(i in 1:length(list_group_names)){
# Get the grouping
group_name <- list_group_names[[i]]
print(group_name)
# We transform the residuals according to the groups
df[[paste0("residuals",group_name)]] <- transformed_residuals(df_result,group_name,method=method)
print(head(df[[paste0("residuals",group_name)]],10))
# We choose the classification method and look at the results
response_var <- paste0("residuals", group_name)
response_var <- paste0("`", response_var, "`")
f <- paste0(response_var, " ~ ", paste(predictors, collapse = " + "))
formula <- as.formula(f)
tree <- rpart(formula, data = df)
prediction <- predict(tree)
# We calculate metrics
true <- df[[paste0("residuals",group_name)]]
n <- nrow(df_result)
MSE <- mean((true-prediction)^2)
RMSE <- sqrt(MSE)
MAE <- mean(abs(true-prediction))
R.squared <- 1 - sum((true-prediction)^2)/sum((true-mean(true))^2)
R.squared.adjusted <- 1 - (1-R.squared)*(n-1)/(n-length(predictors)-1)
res <- rbind(res, data.frame(
group_name = group_name,
average_group_size=sum(df_result[[group_name]]=="average")/nrow(df_result),
MSE =MSE,
RMSE = RMSE,
MAE=MAE,
R.squared=R.squared,
R.squared.adjusted=R.squared.adjusted))
}
return(res)
}
# Regression tree to predict transformed residuals
df_perf_regression_tree <- regression_tree(df,df_result_BDI_Engagement,groups_to_test,predictors = explication_vars,method = "log_multiply")
# Visualization of the result
df_long <- df_perf_regression_tree %>%
pivot_longer(cols = c(R.squared, R.squared.adjusted),
names_to = "metric",
values_to = "value")
plot_performance <- ggplot(df_long, aes(x = average_group_size, y = value, color = metric)) +
geom_line(size = 1) +
geom_point() +
labs(title = "Performance Metrics vs. Group Size",
x = "Average Group Size",
y = "Performance",
color = "Metric") +
theme_minimal()
df_long <- df_perf_regression_tree %>%
pivot_longer(cols = c(MAE,RMSE),
names_to = "metric",
values_to = "value")
plot_error <- ggplot(df_long, aes(x = average_group_size, y = value, color = metric)) +
geom_line(size = 1) +
geom_point() +
labs(title = "Performance Metrics vs. Group Size",
x = "Average Group Size",
y = "Error",
color = "Metric") +
theme_minimal()
grid.arrange(plot_performance,plot_error, ncol = 2)
df_perf_regression_tree <- regression_tree(df,df_result_BDI_Engagement,groups_to_test,predictors = explication_vars,method = "log_multiply_divide")
# Visualization of the result
df_long <- df_perf_regression_tree %>%
pivot_longer(cols = c(R.squared, R.squared.adjusted),
names_to = "metric",
values_to = "value")
plot_performance <- ggplot(df_long, aes(x = average_group_size, y = value, color = metric)) +
geom_line(size = 1) +
geom_point() +
labs(title = "Performance Metrics vs. Group Size",
x = "Average Group Size",
y = "Performance",
color = "Metric") +
theme_minimal()
df_long <- df_perf_regression_tree %>%
pivot_longer(cols = c(MAE,RMSE),
names_to = "metric",
values_to = "value")
plot_error <- ggplot(df_long, aes(x = average_group_size, y = value, color = metric)) +
geom_line(size = 1) +
geom_point() +
labs(title = "Performance Metrics vs. Group Size",
x = "Average Group Size",
y = "Error",
color = "Metric") +
theme_minimal()
grid.arrange(plot_performance,plot_error, ncol = 2)
df_perf_regression_tree <- regression_tree(df,df_result_BDI_Engagement,groups_to_test,predictors = explication_vars,method = "multiply_divide")
# Visualization of the result
df_long <- df_perf_regression_tree %>%
pivot_longer(cols = c(R.squared, R.squared.adjusted),
names_to = "metric",
values_to = "value")
plot_performance <- ggplot(df_long, aes(x = average_group_size, y = value, color = metric)) +
geom_line(size = 1) +
geom_point() +
labs(title = "Performance Metrics vs. Group Size",
x = "Average Group Size",
y = "Performance",
color = "Metric") +
theme_minimal()
df_long <- df_perf_regression_tree %>%
pivot_longer(cols = c(MAE,RMSE),
names_to = "metric",
values_to = "value")
plot_error <- ggplot(df_long, aes(x = average_group_size, y = value, color = metric)) +
geom_line(size = 1) +
geom_point() +
labs(title = "Performance Metrics vs. Group Size",
x = "Average Group Size",
y = "Error",
color = "Metric") +
theme_minimal()
grid.arrange(plot_performance,plot_error, ncol = 2)
df_perf_regression_tree <- regression_tree(df,df_result_BDI_Engagement,groups_to_test,predictors = explication_vars,method = "multiply_divide")
# Visualization of the result
df_long <- df_perf_regression_tree %>%
pivot_longer(cols = c(R.squared, R.squared.adjusted),
names_to = "metric",
values_to = "value")
plot_performance <- ggplot(df_long, aes(x = average_group_size, y = value, color = metric)) +
geom_line(size = 1) +
geom_point() +
labs(title = "Performance Metrics vs. Group Size",
x = "Average Group Size",
y = "Performance",
color = "Metric") +
theme_minimal()
df_long <- df_perf_regression_tree %>%
pivot_longer(cols = c(MAE,RMSE),
names_to = "metric",
values_to = "value")
plot_error <- ggplot(df_long, aes(x = average_group_size, y = value, color = metric)) +
geom_line(size = 1) +
geom_point() +
labs(title = "Performance Metrics vs. Group Size",
x = "Average Group Size",
y = "Error",
color = "Metric") +
theme_minimal()
grid.arrange(plot_performance,plot_error, ncol = 2)
df_perf_regression_tree <- regression_tree(df,df_result_BDI_Engagement,groups_to_test,predictors = explication_vars,method = "log_multiply")
# Visualization of the result
df_long <- df_perf_regression_tree %>%
pivot_longer(cols = c(R.squared, R.squared.adjusted),
names_to = "metric",
values_to = "value")
plot_performance <- ggplot(df_long, aes(x = average_group_size, y = value, color = metric)) +
geom_line(size = 1) +
geom_point() +
labs(title = "Performance Metrics vs. Group Size",
x = "Average Group Size",
y = "Performance",
color = "Metric") +
theme_minimal()
df_long <- df_perf_regression_tree %>%
pivot_longer(cols = c(MAE,RMSE),
names_to = "metric",
values_to = "value")
plot_error <- ggplot(df_long, aes(x = average_group_size, y = value, color = metric)) +
geom_line(size = 1) +
geom_point() +
labs(title = "Performance Metrics vs. Group Size",
x = "Average Group Size",
y = "Error",
color = "Metric") +
theme_minimal()
grid.arrange(plot_performance,plot_error, ncol = 2)
df_perf_regression_tree <- regression_tree(df,df_result_BDI_Engagement,groups_to_test,predictors = explication_vars,method = "multiply")
# Visualization of the result
df_long <- df_perf_regression_tree %>%
pivot_longer(cols = c(R.squared, R.squared.adjusted),
names_to = "metric",
values_to = "value")
plot_performance <- ggplot(df_long, aes(x = average_group_size, y = value, color = metric)) +
geom_line(size = 1) +
geom_point() +
labs(title = "Performance Metrics vs. Group Size",
x = "Average Group Size",
y = "Performance",
color = "Metric") +
theme_minimal()
df_long <- df_perf_regression_tree %>%
pivot_longer(cols = c(MAE,RMSE),
names_to = "metric",
values_to = "value")
plot_error <- ggplot(df_long, aes(x = average_group_size, y = value, color = metric)) +
geom_line(size = 1) +
geom_point() +
labs(title = "Performance Metrics vs. Group Size",
x = "Average Group Size",
y = "Error",
color = "Metric") +
theme_minimal()
grid.arrange(plot_performance,plot_error, ncol = 2)
df_perf_regression_tree <- regression_tree(df,df_result_BDI_Engagement,groups_to_test,predictors = explication_vars,method = "log_multiply")
# Visualization of the result
df_long <- df_perf_regression_tree %>%
pivot_longer(cols = c(R.squared, R.squared.adjusted),
names_to = "metric",
values_to = "value")
plot_performance <- ggplot(df_long, aes(x = average_group_size, y = value, color = metric)) +
geom_line(size = 1) +
geom_point() +
labs(title = "Performance Metrics vs. Group Size",
x = "Average Group Size",
y = "Performance",
color = "Metric") +
theme_minimal()
df_long <- df_perf_regression_tree %>%
pivot_longer(cols = c(MAE,RMSE),
names_to = "metric",
values_to = "value")
plot_error <- ggplot(df_long, aes(x = average_group_size, y = value, color = metric)) +
geom_line(size = 1) +
geom_point() +
labs(title = "Performance Metrics vs. Group Size",
x = "Average Group Size",
y = "Error",
color = "Metric") +
theme_minimal()
grid.arrange(plot_performance,plot_error, ncol = 2)
?prune
View(df_perf_classification_tree)
df_long <- df_perf_classification_tree  %>%
pivot_longer(cols = c(accuracy,macro_precision,macro_recall,macro_f1),
names_to = "metric",
values_to = "value")
ggplot(df_long, aes(x = null_model, y = value, color = metric)) +
geom_line(size = 1) +
geom_point() +
labs(title = "Performance Metrics vs. Group Size",
x = "Average Group Size",
y = "Performace",
color = "Metric") +
theme_minimal()
df_long <- df_perf_classification_tree  %>%
pivot_longer(cols = c(accuracy,macro_precision,macro_recall,macro_f1),
names_to = "metric",
values_to = "value")
ggplot(df_long, aes(x = null_model, y = value, color = metric)) +
geom_line(size = 0.8) +
geom_point() +
labs(title = "Performance Metrics vs. Group Size",
x = "Average Group Size",
y = "Performace",
color = "Metric") +
theme_minimal()
regression_tree <- function(df,df_result,list_group_names,predictors=explication_vars,method="nothing"){
set.seed(1) # For reproductibility
res <- data.frame()
residuals <- df_result[["residuals"]]
for(i in 1:length(list_group_names)){
# Get the grouping
group_name <- list_group_names[[i]]
print(group_name)
# We transform the residuals according to the groups
df[[paste0("residuals",group_name)]] <- transformed_residuals(df_result,group_name,method=method)
print(head(df[[paste0("residuals",group_name)]],10))
# We choose the classification method and look at the results
response_var <- paste0("residuals", group_name)
response_var <- paste0("`", response_var, "`")
f <- paste0(response_var, " ~ ", paste(predictors, collapse = " + "))
formula <- as.formula(f)
tree <- rpart(formula, data = df)
best <- tree$cptable[which.min(tree$cptable[,"xerror"]),"CP"]
pruned_tree <- prune(tree, cp=best)
prediction <- predict(tree)
# We calculate metrics
true <- df[[paste0("residuals",group_name)]]
n <- nrow(df_result)
MSE <- mean((true-prediction)^2)
RMSE <- sqrt(MSE)
MAE <- mean(abs(true-prediction))
R.squared <- 1 - sum((true-prediction)^2)/sum((true-mean(true))^2)
R.squared.adjusted <- 1 - (1-R.squared)*(n-1)/(n-length(predictors)-1)
res <- rbind(res, data.frame(
group_name = group_name,
average_group_size=sum(df_result[[group_name]]=="average")/nrow(df_result),
MSE =MSE,
RMSE = RMSE,
MAE=MAE,
R.squared=R.squared,
R.squared.adjusted=R.squared.adjusted))
}
return(res)
}
df_perf_regression_tree <- regression_tree(df,df_result_BDI_Engagement,groups_to_test,predictors = explication_vars,method = "log_multiply")
regression_tree <- function(df,df_result,list_group_names,predictors=explication_vars,method="nothing"){
set.seed(1) # For reproductibility
res <- data.frame()
residuals <- df_result[["residuals"]]
for(i in 1:length(list_group_names)){
# Get the grouping
group_name <- list_group_names[[i]]
print(group_name)
# We transform the residuals according to the groups
df[[paste0("residuals",group_name)]] <- transformed_residuals(df_result,group_name,method=method)
print(head(df[[paste0("residuals",group_name)]],10))
# We choose the classification method and look at the results
response_var <- paste0("residuals", group_name)
response_var <- paste0("`", response_var, "`")
f <- paste0(response_var, " ~ ", paste(predictors, collapse = " + "))
formula <- as.formula(f)
tree <- rpart(formula, data = df)
best <- tree$cptable[which.min(tree$cptable[,"xerror"]),"CP"]
print(best)
pruned_tree <- prune(tree, cp=best)
prediction <- predict(tree)
# We calculate metrics
true <- df[[paste0("residuals",group_name)]]
n <- nrow(df_result)
MSE <- mean((true-prediction)^2)
RMSE <- sqrt(MSE)
MAE <- mean(abs(true-prediction))
R.squared <- 1 - sum((true-prediction)^2)/sum((true-mean(true))^2)
R.squared.adjusted <- 1 - (1-R.squared)*(n-1)/(n-length(predictors)-1)
res <- rbind(res, data.frame(
group_name = group_name,
average_group_size=sum(df_result[[group_name]]=="average")/nrow(df_result),
MSE =MSE,
RMSE = RMSE,
MAE=MAE,
R.squared=R.squared,
R.squared.adjusted=R.squared.adjusted))
}
return(res)
}
# Regression tree to predict transformed residuals
df_perf_regression_tree <- regression_tree(df,df_result_BDI_Engagement,groups_to_test,predictors = explication_vars,method = "log_multiply")
regression_tree <- function(df,df_result,list_group_names,predictors=explication_vars,method="nothing"){
set.seed(1) # For reproductibility
res <- data.frame()
residuals <- df_result[["residuals"]]
for(i in 1:length(list_group_names)){
# Get the grouping
group_name <- list_group_names[[i]]
print(group_name)
# We transform the residuals according to the groups
df[[paste0("residuals",group_name)]] <- transformed_residuals(df_result,group_name,method=method)
# We choose the classification method and look at the results
response_var <- paste0("residuals", group_name)
response_var <- paste0("`", response_var, "`")
f <- paste0(response_var, " ~ ", paste(predictors, collapse = " + "))
formula <- as.formula(f)
tree <- rpart(formula, data = df)
best <- tree$cptable[which.min(tree$cptable[,"xerror"]),"CP"]
print(best)
pruned_tree <- rpart::prune(tree, cp=best)
prediction <- predict(tree)
# We calculate metrics
true <- df[[paste0("residuals",group_name)]]
n <- nrow(df_result)
MSE <- mean((true-prediction)^2)
RMSE <- sqrt(MSE)
MAE <- mean(abs(true-prediction))
R.squared <- 1 - sum((true-prediction)^2)/sum((true-mean(true))^2)
R.squared.adjusted <- 1 - (1-R.squared)*(n-1)/(n-length(predictors)-1)
res <- rbind(res, data.frame(
group_name = group_name,
average_group_size=sum(df_result[[group_name]]=="average")/nrow(df_result),
MSE =MSE,
RMSE = RMSE,
MAE=MAE,
R.squared=R.squared,
R.squared.adjusted=R.squared.adjusted))
}
return(res)
}
# Regression tree to predict transformed residuals
df_perf_regression_tree <- regression_tree(df,df_result_BDI_Engagement,groups_to_test,predictors = explication_vars,method = "log_multiply")
View(df_perf_regression_tree)
regression_tree <- function(df,df_result,list_group_names,predictors=explication_vars,method="nothing"){
set.seed(1) # For reproductibility
res <- data.frame()
residuals <- df_result[["residuals"]]
for(i in 1:length(list_group_names)){
# Get the grouping
group_name <- list_group_names[[i]]
print(group_name)
# We transform the residuals according to the groups
df[[paste0("residuals",group_name)]] <- transformed_residuals(df_result,group_name,method=method)
# We choose the classification method and look at the results
response_var <- paste0("residuals", group_name)
response_var <- paste0("`", response_var, "`")
f <- paste0(response_var, " ~ ", paste(predictors, collapse = " + "))
formula <- as.formula(f)
tree <- rpart(formula, data = df)
best <- tree$cptable[which.min(tree$cptable[,"xerror"]),"CP"]
print(best)
pruned_tree <- rpart::prune(tree, cp=best)
prediction <- predict(pruned_tree)
# We calculate metrics
true <- df[[paste0("residuals",group_name)]]
n <- nrow(df_result)
MSE <- mean((true-prediction)^2)
RMSE <- sqrt(MSE)
MAE <- mean(abs(true-prediction))
R.squared <- 1 - sum((true-prediction)^2)/sum((true-mean(true))^2)
R.squared.adjusted <- 1 - (1-R.squared)*(n-1)/(n-length(predictors)-1)
res <- rbind(res, data.frame(
group_name = group_name,
average_group_size=sum(df_result[[group_name]]=="average")/nrow(df_result),
MSE =MSE,
RMSE = RMSE,
MAE=MAE,
R.squared=R.squared,
R.squared.adjusted=R.squared.adjusted))
}
return(res)
}
# Regression tree to predict transformed residuals
df_perf_regression_tree <- regression_tree(df,df_result_BDI_Engagement,groups_to_test,predictors = explication_vars,method = "log_multiply")
regression_tree <- function(df,df_result,list_group_names,predictors=explication_vars,method="nothing"){
set.seed(1) # For reproductibility
res <- data.frame()
residuals <- df_result[["residuals"]]
for(i in 1:length(list_group_names)){
# Get the grouping
group_name <- list_group_names[[i]]
print(group_name)
# We transform the residuals according to the groups
df[[paste0("residuals",group_name)]] <- transformed_residuals(df_result,group_name,method=method)
# We choose the classification method and look at the results
response_var <- paste0("residuals", group_name)
response_var <- paste0("`", response_var, "`")
f <- paste0(response_var, " ~ ", paste(predictors, collapse = " + "))
formula <- as.formula(f)
tree <- rpart(formula, data = df)
best <- tree$cptable[which.min(tree$cptable[,"xerror"]),"CP"]
print(best)
pruned_tree <- rpart::prune(tree, cp=best)
prediction <- predict(pruned_tree)
# We calculate metrics
true <- df[[paste0("residuals",group_name)]]
n <- nrow(df_result)
MSE <- mean((true-prediction)^2)
RMSE <- sqrt(MSE)
MAE <- mean(abs(true-prediction))
R.squared <- 1 - sum((true-prediction)^2)/sum((true-mean(true))^2)
R.squared.adjusted <- 1 - (1-R.squared)*(n-1)/(n-length(predictors)-1)
res <- rbind(res, data.frame(
group_name = group_name,
average_group_size=sum(df_result[[group_name]]=="average")/nrow(df_result),
MSE =MSE,
RMSE = RMSE,
MAE=MAE,
R.squared=R.squared,
R.squared.adjusted=R.squared.adjusted))
}
return(res)
}
# Regression tree to predict transformed residuals
df_perf_regression_tree <- regression_tree(df,df_result_BDI_Engagement,groups_to_test,predictors = explication_vars,method = "nothing")
regression_tree <- function(df,df_result,list_group_names,predictors=explication_vars,method="nothing"){
set.seed(1) # For reproductibility
res <- data.frame()
residuals <- df_result[["residuals"]]
for(i in 1:length(list_group_names)){
# Get the grouping
group_name <- list_group_names[[i]]
print(group_name)
# We transform the residuals according to the groups
df[[paste0("residuals",group_name)]] <- transformed_residuals(df_result,group_name,method=method)
# We choose the classification method and look at the results
response_var <- paste0("residuals", group_name)
response_var <- paste0("`", response_var, "`")
f <- paste0(response_var, " ~ ", paste(predictors, collapse = " + "))
formula <- as.formula(f)
tree <- rpart(formula, data = df)
prediction <- predict(tree)
# We calculate metrics
true <- df[[paste0("residuals",group_name)]]
n <- nrow(df_result)
MSE <- mean((true-prediction)^2)
RMSE <- sqrt(MSE)
MAE <- mean(abs(true-prediction))
R.squared <- 1 - sum((true-prediction)^2)/sum((true-mean(true))^2)
R.squared.adjusted <- 1 - (1-R.squared)*(n-1)/(n-length(predictors)-1)
res <- rbind(res, data.frame(
group_name = group_name,
average_group_size=sum(df_result[[group_name]]=="average")/nrow(df_result),
MSE =MSE,
RMSE = RMSE,
MAE=MAE,
R.squared=R.squared,
R.squared.adjusted=R.squared.adjusted))
}
return(res)
}
# Regression tree to predict transformed residuals
df_perf_regression_tree <- regression_tree(df,df_result_BDI_Engagement,groups_to_test,predictors = explication_vars,method = "nothing")
