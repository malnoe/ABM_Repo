# Adjusted linear model
lm_adjusted <- lm(as.formula(paste(outcome, "~", adversity)), data = df_clean)
print("--- Adjusted model :")
print(summary(lm_adjusted))
# Residuals of the adjusted linear model
predicted_all <- predict(lm_adjusted, newdata = df)
residuals_all <- df[[outcome]] - predicted_all
# Bayesian glm for credibility intervals
lm_adjusted_cred <- stan_glm(as.formula(paste(outcome, "~", adversity)), data = df)
# Plot
# Influencer binary value to plot
df_plot <- df %>%
mutate(influencer = FALSE)
df_plot$influencer[original_indices] <- TRUE
# Lines
lines_df <- data.frame(
intercept = c(coef(lm_unadjusted)[1],
coef(lm_adjusted)[1]),
slope = c(coef(lm_unadjusted)[2],
coef(lm_adjusted)[2]),
model = c("Unadjusted", "Adjusted")
)
# ggplot
plot <- ggplot(df_plot, aes_string(x = adversity, y = outcome)) +
# Influencers
geom_point(aes(shape = influencer), size = 2) +
# Regression lines
geom_abline(data = lines_df,
aes(intercept = intercept, slope = slope, color = model),
size = 0.8)+
# Legend
scale_color_manual(values = c("Unadjusted" = "skyblue",
"Adjusted" = "forestgreen"),
name="Model") +
scale_shape_manual(values = c(`FALSE` = 1, `TRUE` = 16),
labels = c("Normal", "Influencer"),
name = "Point type") +
labs(
x = xlab,
y = ylab,
title = main
) +
theme_minimal(base_size = 12) +
theme(
plot.title = element_text(size = 10)
)
if(lines_df$slope[[1]] < 0){
plot <-plot + geom_text(x=max(na.omit(df[[adversity]]))-5,y=max(na.omit(df[[outcome]]))-5,label="Resilient",alpha=0.2) + geom_text(x=min(na.omit(df[[adversity]]))+5,y=min(na.omit(df[[outcome]]))+5,label="Vulnerable",alpha=0.2)
}
else{
plot <- plot + geom_text(x=min(na.omit(df[[adversity]]))+5,y=max(na.omit(df[[outcome]]))-5,label="Vulnerable",alpha=0.2) + geom_text(x=max(na.omit(df[[adversity]]))-5,y=min(na.omit(df[[outcome]]))+5,label="Resilient",alpha=0.2)
}
return(list(plot=plot,
influencers_indices=original_indices,
lm_adjusted=lm_adjusted,
lm_adjusted_cred=lm_adjusted_cred,
residuals_adjusted=residuals_all))
}
## Results : ###########
# CPTS explaining WES
adjusted_fit(df=df_CA,adversity="T1_CPTS",outcome="T1_WES_total",main="Adjusted and unadjusted linear regression for CPTS and WES for Canada at T1",xlab="CPTS",ylab="WES")
adjusted_fit(df=df_CA,adversity="T1_CPTS",outcome="T1_BDI_II",main="Adjusted and unadjusted linear regression for CPTS and BDI for Canada at T1",xlab="CPTS",ylab="BDI-II")
adjusted_fit <- function(df,adversity,outcome,main="Adjusted and unadjusted linear regression",xlab="Adversity",ylab="Outcome"){
# Unadjusted linear model
lm_unadjusted <- lm(as.formula(paste(outcome, "~", adversity)), data = df)
print("--- Unadjusted model :")
print(summary(lm_unadjusted))
# Identification of influencial points using Cook's D.
used_data <- model.frame(lm_unadjusted)
influencial_points <- which(cooks.distance(lm_unadjusted) > 4 / nrow(used_data))
used_rows <- as.numeric(rownames(used_data))
original_indices <- used_rows[influencial_points]
# Cleaned data for the LM
df_clean <- df[-original_indices, ]
# Adjusted linear model
lm_adjusted <- lm(as.formula(paste(outcome, "~", adversity)), data = df_clean)
print("--- Adjusted model :")
print(summary(lm_adjusted))
# Residuals of the adjusted linear model
predicted_all <- predict(lm_adjusted, newdata = df)
residuals_all <- df[[outcome]] - predicted_all
# Bayesian glm for credibility intervals
lm_adjusted_cred <- stan_glm(as.formula(paste(outcome, "~", adversity)), data = df)
# Plot
# Influencer binary value to plot
df_plot <- df %>%
mutate(influencer = FALSE)
df_plot$influencer[original_indices] <- TRUE
# Lines
lines_df <- data.frame(
intercept = c(coef(lm_unadjusted)[1],
coef(lm_adjusted)[1]),
slope = c(coef(lm_unadjusted)[2],
coef(lm_adjusted)[2]),
model = c("Unadjusted", "Adjusted")
)
# ggplot
plot <- ggplot(df_plot, aes_string(x = adversity, y = outcome)) +
# Influencers
geom_point(aes(shape = influencer), size = 2) +
# Regression lines
geom_abline(data = lines_df,
aes(intercept = intercept, slope = slope, color = model),
size = 0.8)+
# Legend
scale_color_manual(values = c("Unadjusted" = "skyblue",
"Adjusted" = "forestgreen"),
name="Model") +
scale_shape_manual(values = c(`FALSE` = 1, `TRUE` = 16),
labels = c("Normal", "Influencer"),
name = "Point type") +
labs(
x = xlab,
y = ylab,
title = main
) +
theme_minimal(base_size = 12) +
theme(
plot.title = element_text(size = 10)
)
if(lines_df$slope[[1]] < 0){
plot <-plot + geom_text(x=max(na.omit(df[[adversity]]))-5,y=max(na.omit(df[[outcome]]))-5,label="Resilient",alpha=0.2,color="grey") + geom_text(x=min(na.omit(df[[adversity]]))+5,y=min(na.omit(df[[outcome]]))+5,label="Vulnerable",alpha=0.2,color="grey")
}
else{
plot <- plot + geom_text(x=min(na.omit(df[[adversity]]))+5,y=max(na.omit(df[[outcome]]))-5,label="Vulnerable",alpha=0.2,color="grey") + geom_text(x=max(na.omit(df[[adversity]]))-5,y=min(na.omit(df[[outcome]]))+5,label="Resilient",alpha=0.2,color="grey")
}
return(list(plot=plot,
influencers_indices=original_indices,
lm_adjusted=lm_adjusted,
lm_adjusted_cred=lm_adjusted_cred,
residuals_adjusted=residuals_all))
}
## Results : ###########
# CPTS explaining WES
adjusted_fit(df=df_CA,adversity="T1_CPTS",outcome="T1_WES_total",main="Adjusted and unadjusted linear regression for CPTS and WES for Canada at T1",xlab="CPTS",ylab="WES")
#adjusted_fit(df=df_CA,adversity="T2_CPTS",outcome="T2_WES_total",main="Adjusted and unadjusted linear regression for CPTS and WES for Canada at T2",xlab="CPTS",ylab="WES")
# BDI explaining SES
#adjusted_fit(df=df_SA,adversity="T1_BDI_II",outcome="T1_SES_total_T2",main="Adjusted and unadjusted linear regression for BDI and SES for SA at T1",xlab="BDI-II",ylab="SES")
#adjusted_fit(df=df_CA,adversity="T1_BDI_II",outcome="T1_SES_total_T2",main="Adjusted and unadjusted linear regression for BDI and SES for Canada at T1",xlab="BDI-II",ylab="SES")
#adjusted_fit(df=df_SA,adversity="T2_BDI_II",outcome="T2_SES_total",main="Adjusted and unadjusted linear regression for BDI and SES for SA at T2",xlab="BDI-II",ylab="SES")
#adjusted_fit(df=df_CA,adversity="T2_BDI_II",outcome="T2_SES_total",main="Adjusted and unadjusted linear regression for BDI and SES for Canada at T2",xlab="BDI-II",ylab="SES")
#adjusted_fit(df=df_CA,adversity="T1_FAS",outcome="T1_BDI_II",main="Adjusted and unadjusted linear regression for FAS and BDI for Canada at T1",xlab="FAS",ylab="BDI-II")
# CPTS explaining BDI
adjusted_fit(df=df_CA,adversity="T1_CPTS",outcome="T1_BDI_II",main="Adjusted and unadjusted linear regression for CPTS and BDI for Canada at T1",xlab="CPTS",ylab="BDI-II")
#adjusted_fit(df=df_SA,adversity="T1_CPTS",outcome="T1_BDI_II",main="Adjusted and unadjusted linear regression for CPTS and BDI for SA at T1",xlab="CPTS",ylab="BDI-II")
#adjusted_fit(df=df_CA,adversity="T2_CPTS",outcome="T2_BDI_II",main="Adjusted and unadjusted linear regression for CPTS and BDI for Canada at T2",xlab="CPTS",ylab="BDI-II")
# Visualization of the intervals
visualisation_confidence_intervals <- function(df, adversity, outcome, adjusted_lm, preds, labels, main = "Intervals") {
# Adjusted linear model coefficients
intercept <- coef(adjusted_lm)[1]
slope     <- coef(adjusted_lm)[2]
# Base graph with points and regression line
plot <- ggplot(df, aes(x = .data[[adversity]], y = .data[[outcome]])) +
geom_point() +
geom_abline(intercept = intercept, slope = slope, color = "grey", linetype = "solid") +
labs(
x = adversity,
y = outcome,
title = main,
fill = "Interval"
) +
theme_minimal(base_size = 10) +
theme(plot.title = element_text(size = 10))
# Combine all intervals in one dataframe
all_preds <- do.call(rbind, lapply(seq_along(preds), function(i) {
pred <- preds[[i]]
pred[[outcome]]   <- df[[outcome]]
pred[[adversity]] <- df[[adversity]]
pred$label <- labels[i]
pred
}))
all_preds$label <- factor(all_preds$label, levels = labels)
# Ribbons with legend for each interval
plot <- plot +
geom_ribbon(
data = all_preds,
aes(
x = .data[[adversity]],
ymin = lwr,
ymax = upr,
fill = label,
group = label
),
alpha = 0.4,
inherit.aes = FALSE
)
if(slope < 0){
plot <-plot + geom_text(x=max(na.omit(df[[adversity]]))-5,y=max(na.omit(df[[outcome]]))-5,label="Resilient",alpha=0.2,color="grey") + geom_text(x=min(na.omit(df[[adversity]]))+5,y=min(na.omit(df[[outcome]]))+5,label="Vulnerable",alpha=0.2,color="grey")
}
else{
plot <- plot + geom_text(x=min(na.omit(df[[adversity]]))+5,y=max(na.omit(df[[outcome]]))-5,label="Vulnerable",alpha=0.2,color="grey") + geom_text(x=max(na.omit(df[[adversity]]))-5,y=min(na.omit(df[[outcome]]))+5,label="Resilient",alpha=0.2,color="grey")
}
return(plot)
}
## Quantile residuals : ####
# We want the quantile_sub lowest residuals and quantile_sup biggest residuals
get_groups_quantile <- function(residuals,quantile_sub,quantile_sup,is_resilience_positive){
n <- sum(!is.na(residuals))
n_sub <- trunc(n*quantile_sub)
n_sup <- trunc(n*quantile_sup)
index_ordered_residuals <- order(residuals)
res <- rep(NA, length(residuals))
res[!is.na(residuals)] <- "average"
if(is_resilience_positive){
# Lowest residuals -> vulnerable
for(i in 1:n_sub){
index <- index_ordered_residuals[i]
res[[index]] <- "vulnerable"
}
# Biggest residuals -> resilient
for(i in n:(n-n_sup)){
index <- index_ordered_residuals[i]
res[[index]] <- "resilient"
}
}
else{
# Lowest residuals -> resilient
for(i in 1:n_sub){
index <- index_ordered_residuals[i]
res[[index]] <- "resilient"
}
# Biggest residuals -> vulnerable
for(i in n:(n-n_sup)){
index <- index_ordered_residuals[i]
res[[index]] <- "vulnerable"
}
}
return(res)
}
## Credibility residuals : ##########
# We can do the same with a bayesian approach with a credibility interval (for the mean and for predicted values)
# Function to build the credibility intervals from the bayesian adjusted lm
get_credibility_intervals <- function(lm_adjusted_cred,newdata,lwr=0.025,upr=0.975){
complete_rows <- complete.cases(newdata)
# Posterior linear prediction on complete cases
preds <- posterior_linpred(lm_adjusted_cred,
newdata = newdata[!is.na(newdata[,c(adversity_string)]),],
draws = 1000,
transform = TRUE)
# Ensure preds is a matrix with rows = draws, cols = observations
if (is.null(dim(preds))) {
preds <- matrix(preds, nrow = 1000)
}
# Compute credible intervals per observation (apply over columns)
intervals <- t(apply(preds, 2, quantile, probs = c(lwr, upr)))
# Formating the result
res <- data.frame(lwr=c(), upr=c())
counter <- 1
# Adding NA
for(i in 1:nrow(newdata)){
if(!is.na(newdata[i,1])){
res[i,"lwr"] <- intervals[counter,1]
res[i,"upr"] <- intervals[counter,2]
counter <- counter + 1
}
else{
res[i,"lwr"] <- NA
res[i,"upr"] <- NA
}
}
return(res)
}
## Presentation ##########
# Example 1
df <- df_CA
adversity_string <- "T1_CPTS"
outcome_string <- "T1_BDI_II"
outcome <- df_CA$T1_BDI_II
resilience_sign <- FALSE
res <- adjusted_fit(df=df,adversity=adversity_string,outcome=outcome_string)
# Example 2
#df <- df_CA
#adversity_string <- "T1_CPTS"
#outcome_string <- "T1_WES_total"
#outcome <- df_CA$T1_WES_total
#resilience_sign <- TRUE
#res <- adjusted_fit(df=df_CA,adversity="T1_CPTS",outcome="T1_WES_total",main="Adjusted and unadjusted linear regression for CPTS and WES for Canada at T1",xlab="CPTS",ylab="WES")
# Get the info
lm_adjusted <- res$lm_adjusted
lm_adjusted_cred <- res$lm_adjusted_cred
residuals <- res$residuals_adjusted
plot <- res$plot
# Raw residuals
groups_raw <- get_groups_residuals(residuals,is_resilience_positive=resilience_sign)
df_n_groups <- data.frame(resilient = sum(groups_raw=="resilient", na.rm=TRUE), average = sum(groups_raw=="average", na.rm=TRUE), vulnerable = sum(groups_raw=="vulnerable", na.rm=TRUE), row.names=c("raw residuals"))
# Confidence intervals
# Prediction
preds_conf <- list(
as.data.frame(predict(lm_adjusted, newdata = df, interval = "prediction", level = 0.75)),
as.data.frame(predict(lm_adjusted, newdata = df, interval = "prediction", level = 0.6)),
as.data.frame(predict(lm_adjusted, newdata = df, interval = "prediction", level = 0.5)),
as.data.frame(predict(lm_adjusted, newdata = df, interval = "confidence", level = 0.99)),
as.data.frame(predict(lm_adjusted, newdata = df, interval = "confidence", level = 0.95))
)
# Names for the predictions
names_conf <- list(
"pred. residuals (75%)",
"pred. residuals (60%)",
"pred. residuals (50%)",
"conf. residuals (99%)",
"conf. residuals (95%)"
)
# Get groups and update df_n_groups
groups_confidence <- list()
for(i in 1:length(preds_conf)){
groups <- get_groups_confidence(outcome, preds_conf[[i]],is_resilience_positive=resilience_sign)
groups_confidence[[ names_conf[[i]] ]] <- groups
df_n_groups <- rbind(df_n_groups,
data.frame(resilient = sum(groups=="resilient", na.rm=TRUE), average = sum(groups=="average", na.rm=TRUE), vulnerable = sum(groups=="vulnerable", na.rm=TRUE), row.names=c(names_conf[[i]])))
}
visualisation_confidence_intervals(df=df,adversity=adversity_string,outcome=outcome_string,adjusted_lm =lm_adjusted,preds_conf,names_conf,main="Confidence intervals")
# Quantiles
# Quantile values -> Can be asymetric (looking at the QQ-plot ?)
list_quantile_sub <- list(0.05,0.1,0.15,0.25)
list_quantile_sup <- list(0.05,0.1,0.15,0.25)
# Names
names <- list(
"quantiles (5%)",
"quantiles (10%)",
"quantiles (15%)",
"quantiles (25%)"
)
# Get groups and update df_n_groups
groups_quantile <- list()
for(i in 1:length(list_quantile_sub)){
groups <- get_groups_quantile(residuals,list_quantile_sub[[i]],list_quantile_sup[[i]],is_resilience_positive=resilience_sign)
groups_quantile[[ names[[i]] ]] <- groups
df_n_groups <- rbind(df_n_groups,
data.frame(resilient = sum(groups=="resilient", na.rm=TRUE), average = sum(groups=="average", na.rm=TRUE), vulnerable = sum(groups=="vulnerable", na.rm=TRUE), row.names=c(names[[i]])))
}
# Credibility intervals
# Predictions
preds_cred <- list(
get_credibility_intervals(lm_adjusted_cred,newdata=df[c(adversity_string)],lwr=0.0005,upr=0.9995),
get_credibility_intervals(lm_adjusted_cred,newdata=df[c(adversity_string)],lwr=0.005,upr=0.995),
get_credibility_intervals(lm_adjusted_cred,newdata=df[c(adversity_string)],lwr=0.025,upr=0.975),
get_credibility_intervals(lm_adjusted_cred,newdata=df[c(adversity_string)],lwr=0.05,upr=0.95),
get_credibility_intervals(lm_adjusted_cred,newdata=df[c(adversity_string)],lwr=0.125,upr=0.875)
)
# Names for the predictions
names_cred <- list(
"cred. 99.9%",
"cred. 99%",
"cred. 95%",
"cred. 90%",
"cred. 75%"
)
# Get groups and update df_n_groups
groups_credibility <- list()
for(i in 1:length(preds_cred)){
groups <- get_groups_confidence(outcome, preds_cred[[i]],is_resilience_positive=resilience_sign)
groups_credibility[[ names_cred[[i]] ]] <- groups
df_n_groups <- rbind(df_n_groups,
data.frame(resilient = sum(groups=="resilient", na.rm=TRUE), average = sum(groups=="average", na.rm=TRUE), vulnerable = sum(groups=="vulnerable", na.rm=TRUE), row.names=c(names_cred[[i]])))
}
visualisation_confidence_intervals(df=df,adversity=adversity_string,outcome=outcome_string,adjusted_lm =lm_adjusted,preds_cred,names_cred,main="Credibility intervals")
df <- df_CA
adversity_string <- "T1_CPTS"
outcome_string <- "T1_WES_total"
outcome <- df_CA$T1_WES_total
resilience_sign <- TRUE
res <- adjusted_fit(df=df_CA,adversity="T1_CPTS",outcome="T1_WES_total",main="Adjusted and unadjusted linear regression for CPTS and WES for Canada at T1",xlab="CPTS",ylab="WES")
# Get the info
lm_adjusted <- res$lm_adjusted
lm_adjusted_cred <- res$lm_adjusted_cred
residuals <- res$residuals_adjusted
plot <- res$plot
# Raw residuals
groups_raw <- get_groups_residuals(residuals,is_resilience_positive=resilience_sign)
df_n_groups <- data.frame(resilient = sum(groups_raw=="resilient", na.rm=TRUE), average = sum(groups_raw=="average", na.rm=TRUE), vulnerable = sum(groups_raw=="vulnerable", na.rm=TRUE), row.names=c("raw residuals"))
# Confidence intervals
# Prediction
preds_conf <- list(
as.data.frame(predict(lm_adjusted, newdata = df, interval = "prediction", level = 0.75)),
as.data.frame(predict(lm_adjusted, newdata = df, interval = "prediction", level = 0.6)),
as.data.frame(predict(lm_adjusted, newdata = df, interval = "prediction", level = 0.5)),
as.data.frame(predict(lm_adjusted, newdata = df, interval = "confidence", level = 0.99)),
as.data.frame(predict(lm_adjusted, newdata = df, interval = "confidence", level = 0.95))
)
# Names for the predictions
names_conf <- list(
"pred. residuals (75%)",
"pred. residuals (60%)",
"pred. residuals (50%)",
"conf. residuals (99%)",
"conf. residuals (95%)"
)
# Get groups and update df_n_groups
groups_confidence <- list()
for(i in 1:length(preds_conf)){
groups <- get_groups_confidence(outcome, preds_conf[[i]],is_resilience_positive=resilience_sign)
groups_confidence[[ names_conf[[i]] ]] <- groups
df_n_groups <- rbind(df_n_groups,
data.frame(resilient = sum(groups=="resilient", na.rm=TRUE), average = sum(groups=="average", na.rm=TRUE), vulnerable = sum(groups=="vulnerable", na.rm=TRUE), row.names=c(names_conf[[i]])))
}
visualisation_confidence_intervals(df=df,adversity=adversity_string,outcome=outcome_string,adjusted_lm =lm_adjusted,preds_conf,names_conf,main="Confidence intervals")
# Quantiles
# Quantile values -> Can be asymetric (looking at the QQ-plot ?)
list_quantile_sub <- list(0.05,0.1,0.15,0.25)
list_quantile_sup <- list(0.05,0.1,0.15,0.25)
# Names
names <- list(
"quantiles (5%)",
"quantiles (10%)",
"quantiles (15%)",
"quantiles (25%)"
)
# Get groups and update df_n_groups
groups_quantile <- list()
for(i in 1:length(list_quantile_sub)){
groups <- get_groups_quantile(residuals,list_quantile_sub[[i]],list_quantile_sup[[i]],is_resilience_positive=resilience_sign)
groups_quantile[[ names[[i]] ]] <- groups
df_n_groups <- rbind(df_n_groups,
data.frame(resilient = sum(groups=="resilient", na.rm=TRUE), average = sum(groups=="average", na.rm=TRUE), vulnerable = sum(groups=="vulnerable", na.rm=TRUE), row.names=c(names[[i]])))
}
# Credibility intervals
# Predictions
preds_cred <- list(
get_credibility_intervals(lm_adjusted_cred,newdata=df[c(adversity_string)],lwr=0.0005,upr=0.9995),
get_credibility_intervals(lm_adjusted_cred,newdata=df[c(adversity_string)],lwr=0.005,upr=0.995),
get_credibility_intervals(lm_adjusted_cred,newdata=df[c(adversity_string)],lwr=0.025,upr=0.975),
get_credibility_intervals(lm_adjusted_cred,newdata=df[c(adversity_string)],lwr=0.05,upr=0.95),
get_credibility_intervals(lm_adjusted_cred,newdata=df[c(adversity_string)],lwr=0.125,upr=0.875)
)
# Names for the predictions
names_cred <- list(
"cred. 99.9%",
"cred. 99%",
"cred. 95%",
"cred. 90%",
"cred. 75%"
)
# Get groups and update df_n_groups
groups_credibility <- list()
for(i in 1:length(preds_cred)){
groups <- get_groups_confidence(outcome, preds_cred[[i]],is_resilience_positive=resilience_sign)
groups_credibility[[ names_cred[[i]] ]] <- groups
df_n_groups <- rbind(df_n_groups,
data.frame(resilient = sum(groups=="resilient", na.rm=TRUE), average = sum(groups=="average", na.rm=TRUE), vulnerable = sum(groups=="vulnerable", na.rm=TRUE), row.names=c(names_cred[[i]])))
}
visualisation_confidence_intervals(df=df,adversity=adversity_string,outcome=outcome_string,adjusted_lm =lm_adjusted,preds_cred,names_cred,main="Credibility intervals")
## Results
View(df_n_groups)
groups_raw
groups_confidence
groups_quantile
groups_credibility
preds_cred <- list(
get_credibility_intervals(lm_adjusted_cred,newdata=df[c(adversity_string)],lwr=0.005,upr=0.995),
get_credibility_intervals(lm_adjusted_cred,newdata=df[c(adversity_string)],lwr=0.025,upr=0.975),
get_credibility_intervals(lm_adjusted_cred,newdata=df[c(adversity_string)],lwr=0.05,upr=0.95),
get_credibility_intervals(lm_adjusted_cred,newdata=df[c(adversity_string)],lwr=0.125,upr=0.875),
get_credibility_intervals(lm_adjusted_cred,newdata=df[c(adversity_string)],lwr=0.25,upr=0.75)
)
# Names for the predictions
names_cred <- list(
"cred. 99%",
"cred. 95%",
"cred. 90%",
"cred. 75%",
"cred. 50%"
)
# Get groups and update df_n_groups
groups_credibility <- list()
for(i in 1:length(preds_cred)){
groups <- get_groups_confidence(outcome, preds_cred[[i]],is_resilience_positive=resilience_sign)
groups_credibility[[ names_cred[[i]] ]] <- groups
df_n_groups <- rbind(df_n_groups,
data.frame(resilient = sum(groups=="resilient", na.rm=TRUE), average = sum(groups=="average", na.rm=TRUE), vulnerable = sum(groups=="vulnerable", na.rm=TRUE), row.names=c(names_cred[[i]])))
}
visualisation_confidence_intervals(df=df,adversity=adversity_string,outcome=outcome_string,adjusted_lm =lm_adjusted,preds_cred,names_cred,main="Credibility intervals")
## Results
View(df_n_groups)
groups_raw
groups_confidence
groups_quantile
groups_credibility
preds_cred <- list(
get_credibility_intervals(lm_adjusted_cred,newdata=df[c(adversity_string)],lwr=0.0005,upr=0.9995),
get_credibility_intervals(lm_adjusted_cred,newdata=df[c(adversity_string)],lwr=0.005,upr=0.995),
get_credibility_intervals(lm_adjusted_cred,newdata=df[c(adversity_string)],lwr=0.025,upr=0.975),
get_credibility_intervals(lm_adjusted_cred,newdata=df[c(adversity_string)],lwr=0.05,upr=0.95),
get_credibility_intervals(lm_adjusted_cred,newdata=df[c(adversity_string)],lwr=0.125,upr=0.875),
get_credibility_intervals(lm_adjusted_cred,newdata=df[c(adversity_string)],lwr=0.25,upr=0.75)
)
# Names for the predictions
names_cred <- list(
"cred. 99.9%",
"cred. 99%",
"cred. 95%",
"cred. 90%",
"cred. 75%",
"cred. 50%"
)
# Get groups and update df_n_groups
groups_credibility <- list()
for(i in 1:length(preds_cred)){
groups <- get_groups_confidence(outcome, preds_cred[[i]],is_resilience_positive=resilience_sign)
groups_credibility[[ names_cred[[i]] ]] <- groups
df_n_groups <- rbind(df_n_groups,
data.frame(resilient = sum(groups=="resilient", na.rm=TRUE), average = sum(groups=="average", na.rm=TRUE), vulnerable = sum(groups=="vulnerable", na.rm=TRUE), row.names=c(names_cred[[i]])))
}
visualisation_confidence_intervals(df=df,adversity=adversity_string,outcome=outcome_string,adjusted_lm =lm_adjusted,preds_cred,names_cred,main="Credibility intervals")
## Results
View(df_n_groups)
groups_raw
groups_confidence
groups_quantile
groups_credibility
qqline(residuals)
qqline(residuals)
qqline(residuals)
